Headline::::
Google's artificial intelligence machine to battle human champion of 'Go'




DateTime::::2016-03-07T14:33:15+0000



<p>On Wednesday afternoon in the South Korean capital, Seoul, Lee Se-dol, the 33-year-old master of the ancient Asian board game Go, will sit down to defend humanity.</p>

<p>On the other side of the table will be his opponent: Alphago, a programme built by <a class="u-underline" data-component="auto-linked-tag" data-link-name="auto-linked-tag" href="http://www.theguardian.com/technology/google">Google</a> subsidiary DeepMind which became, in October, the first machine to beat a professional human Go player, the European champion Fan Hui. That match proved that Alphago could hold its own against the best; this one will demonstrate whether “the best” have to relinquish that title entirely.</p>

<p> <span>Related: </span><a class="u-underline" data-component="in-body-link" data-link-name="in body link" href="http://www.theguardian.com/technology/2016/feb/22/google-deepmind-go-alphago">Google throws down the gauntlet. But can anyone beat its computer at Go?</a> </p>

<p>Lee, who is regularly ranked among the top three players alive, has been a Go professional for 21 years; Alphago won its first such match less than 21 weeks ago. Despite that, the computer has already played more games of Go than Lee could hope to fit in his life if he lived to a hundred, and it’s good. Very good.</p>

<p>At the press conference confirming the details of the match, <a class="u-underline" data-component="in-body-link" data-link-name="in body link" href="http://www.theguardian.com/technology/2016/feb/22/google-deepmind-go-alphago">Lee exuded confidence</a>. “I don’t think it will be a very close match,” he told the assembled crowd with a sheepish grin. “I believe it will be 5–0, or maybe 4–1. So the critical point for me will be to not lose one match.”</p>

<p>DeepMind thinks otherwise. The company was founded by Demis Hassabis, a 39-year-old Brit who started the artificial intelligence (AI) research firm after a varied career taking in a neuroscience PhD, blockbuster video game development, and master-level chess – and he puts its chances of winning the match at around 50–50.</p>

<p>Clearly, one of them is wrong. Either Lee has vastly overestimated his chances against a new breed of AI, or Hassabis and company still don’t understand quite how powerful a player they are up against. But the answer to that, revealed over the course of five matches throughout the week, will have ramifications far beyond the world of Go.</p>

<p>On the surface, Go looks simple. Compared with chess – which has six different types of pieces, each with different movement rules, and fiddly additions such as castling and promotion – a Go board is the height of elegance.</p>

<p>Each player takes it in turns placing stones of their colour on a 19-by-19 board, attempting to surround and thus capture their opponent’s pieces. The player who has taken the most territory, by surrounding or occupying it with their own stones, at the end of the game is the winner.</p>

<p>But the simplicity of the ruleset belies the astonishing complexity that the game can demonstrate. The first move of a game of chess offers 28 possibilities; the first move of a game of Go can involve placing the stone in one of 361 positions. A game of chess lasts around 80 turns, while Go games last 150. That leads to a staggering number of possibilities: there are more legal board states for a game of Go or chess than there are atoms in the universe.</p>

<p>And so both chess and go are resistant to the tactic by which simpler games, such as noughts and crosses or draughts (tic-tac-toe and checkers, to Americans), have been “solved”: by enumerating every possible move, and drawing up rules for how to guarantee that a computer will be able to play to at least a draw. Each game is just too complex.<br/></p>

<p>Chess computers can at least rely on a modified version of the same tactic. Such machines, including Deep Blue – the computer made by IBM which beat grandmaster Gary Kasparov in 1997, ushering in an age of dominance by computers in chess – rely on calculating and then judging the value of vast numbers of possible moves. Deep Blue, for instance, could evaluate 200m possible moves in a second. Those machines play by looking into the future, to find the set of moves that will lead them to the strongest position, and then playing them out step by step.</p>

<p>That tactic doesn’t work for Go. Partly, that’s because of one further complication in the game: the immense difficulty of actually evaluating a move. A chess player can easily look at a board and see who is in the stronger position, often simply by counting the number of pieces on the board held by each player.</p>

<p>In Go, such an approach was long thought impossible. And even if that problem could be solved, the sheer scale of the game meant that exhaustively searching through every possible move left the machine far from competitive with even a weak human player. As a result, as recently as 2014, <a class="u-underline" data-component="in-body-link" data-link-name="in body link" href="http://www.wired.com/2014/05/the-world-of-computer-go/">a leading developer of Go software estimated</a> it would be a decade before a machine could beat a professional player. </p>

<p>In fact, it was less than a year.</p>

<p>DeepMind approached the problem </p>

<p> by seeing whether the company could teach a neural network to play Go. The technology, which began with attempts to mimic the way the human brain interprets and processes information, is at the heart of DeepMind’s AI research, and lends itself well to what Hassabis, speaking on the eve of his trip to Seoul to oversee the competition, calls “deep reinforcement learning”.</p>

<p>“It’s the combination of deep learning, neural network stuff, with reinforcement learning,” he explains. “Learning by trial and error, incrementally improving, and learning from your mistakes.”<br/></p>

<p>DeepMind had already used the technique successfully <a class="u-underline" data-component="in-body-link" data-link-name="in body link" href="http://www.theguardian.com/technology/2015/feb/25/google-develops-computer-program-capable-of-learning-tasks-independently">when it built a system capable of learning how to play old Atari video games</a>. But thought rapidly turned to a greater challenge, and one which had for a long time represented a holy grail of AI research. Just two months after the Atari research was published, the team got its initial results on the Go project, Hassabis says. “Then we felt, when we assessed it, that if we put a serious team on to it we could make some pretty fast progress.”</p>

<p>The idea of applying neural networks to solve tricky problems in AI isn’t confined to DeepMind, but the technology is notoriously tricky to refine. Hassabis likens it to teaching a child, rather than programming a computer: even if the team knows what needs to be changed, they can’t simply add a line of code. Instead, they need to show the software enough examples of correct behaviour for it to draw its own inferences.</p>

<p>But DeepMind did hit upon a few genuine breakthroughs. “The big jump was the discovery of the value network, which was last summer,” Hassabis says. That was the realisation that a finely tuned neural network could solve one of the problems previously thought impossible, and learn to predict the winner of a game by looking at the board.</p>

<p>From there, progress was rapid. The value network, paired with a second neural network, the policy network, would work to pick a few possible moves (based on similar plays seen in previous matches) and then estimate which of the resulting board states would be strongest for the AlphaGo player. </p>

<p class="pullquote-paragraph">IBM didn’t publish the paper for years, and then dismantled Deep Blue. They did a few things that fuelled the paranoia.</p>

<p>The second neural network works differently. Called the policy network, it was trained on thousands of matches played by go professionals, with the aim of predicting where they would play the next move. It managed to achieve success 57% of the time, allowing it to very quickly reach a level of competency near that of the best humans.</p>

<p>The policy network on its own is good enough, according to DeepMind, to beat every other go software on the market. But it’s when the two neural networks work in concert that AlphaGo really shines. Meanwhile, a third tool, called Monte Carlo tree search, helps the system play strategically as well as tactically.</p>

<p>Lee’s overconfidence, says Hassabis, is because he hasn’t seen the most recent progress. “He’s very confident, because he looked at the Fan Hui version” that played in October. “And clearly, if we were to play that, he would thrash it.</p>

<p>“I think he’s basing it off that, plus some approximation of how much it might have improved … All I can say is that our tests are leading us to believe that we have a good chance.” As for Lee’s trash talk, Hassabis counters in his own style. “I would be very disappointed if we didn’t win a game – put it that way.”</p>

<p>If DeepMind does win the match, it will be a watershed moment for AI with only one genuine precedent: Deep Blue’s victory over Kasparov in 1997. Hassabis’ chess days were over by then, but he followed the match as closely as he could – given that it fell weeks before his computer science finals at Cambridge (he graduated with a double first). </p>

<p>He recalls being surprised by Deep Blue’s success. “He would say this himself, of course, but I think he was probably at that stage still slightly stronger than Deep Blue. As we know now it was just a matter of time, but at that stage it still wasn’t clear.”</p>

<p>That match was won with the slightest of margins, though Deep Blue’s occasionally erratic play style led to controversy, with Kasparov publicly accusing IBM of cheating in the match. It’s a conflict DeepMind is eager to avoid, and part of the reason the team published its ground-breaking Nature paper, detailing the inner workings of AlphaGo, in advance.</p>

<p>“If you wanted to, with enough effort you could probably recreate AlphaGo from that paper in about a year, if you put enough people on it,” Hassabis says. “Whereas IBM didn’t publish the paper for another five to ten years afterwards, and then they dismantled Deep Blue. So they did a few things that didn’t help, that fuelled the paranoia.”</p>

<p>The chess world has had two decades to live with the fallout of Deep Blue’s victory over Kasparov. But Frederic Friedel, a computer chess pioneer and the founder of the news site ChessBase, argues that it’s possible to overstate the effect the victory had. “AlphaGo winning won’t change the world of Go. It’s like you’ve built a bicycle or a car that can go faster than Usain Bolt, and you say: ‘Look at how fast it is!,” does this mean the world ends for athletics? No, it doesn’t.”</p>

<p>Friedel, who first met Hassabis as “a cocky little kid who came for a dinner with Gary [Kasparov] and myself in London, and told us about some software he was developing”, does have a warning for Go players, though. “The advent of bicycles and motorbikes did not make athletes give up in despair: they just went on racing each other without these machines. But there is a grave difference to the chess analogy: a 200-metre runner cannot secretly use the assistance of a bicycle, but a chess player can most certainly get his moves surreptitiously from a computer.</p>

<p>“Cheating in chess is becoming a serious problem, and it will become more acute as technology progresses. That will change the game dramatically – not the fact that computers are stronger than humans.”</p>

<p>Thinking about what comes after the match is one step too far for Hassabis and DeepMind, who are focusing everything they have on the next two weeks. If they win, attention will probably turn to cleaning up AlphaGo in preparation for a consumer release, and Hassabis hopes that a highly skilled Go programme could be an important step in popularising the game in the west, where would-be stars are often hampered by the lack of opponents to test their mettle against.</p>

<p>And the company has already turned its attention to other, more practical, problems which can be tackled with the same deep reinforcement learning approach that led to AlphaGo. In the short term, that means helping parent company Google with tricky challenges like voice and image recognition, while in the next five or ten years, Hassabis says, “ultimately we want to apply these techniques in important real-world problems, from medical diagnostics to climate modelling”.</p>

<p>But if AlphaGo wins its match against Lee Se-dol, it will mean much more than just a stepping stone in DeepMind’s own progress. One of the last areas of mental competition in which humanity had an advantage over machines will have been vanquished. If you still think you’re better than an AI, now is the time to think again.</p>




Author::::Ben Murphy
DateTime::::2016-03-09T21:10:51Z
Calvinball! Great reference. Not sure how good a computer look in a mask and cape though.



Author::::benjohn
DateTime::::2016-03-09T16:44:26Z
Good write up. 



Author::::benjohn
DateTime::::2016-03-09T16:27:26Z
How would you like to define "intelligence"?



Author::::Declawed
DateTime::::2016-03-09T12:59:28Z
The depressing thing isn't that you don't know you're wrong, it's that the people who know you're wrong are outnumbered by the people who think you're right, and that that means they're right, so they can rightfully shout down the people who are 'wrong'.



Author::::Wiretrip
DateTime::::2016-03-09T11:18:24Z
What is interesting about the Deepmind technology (and where it differs greatly from the image recognition convnets in use elsewhere) is that it uses deep convnets to predict the consequences of a decision over time, even if the 'reward' for a decision will not be apparent for some time after the decision. This *does* have many applications in a more generalised cognitive system so I wouldn't be so sure that this is just a point solution to a single problem (like recognising cats or handwriting).



Author::::ByrneLegacy
DateTime::::2016-03-09T10:18:52Z
Ah, but I reckon the computer doesn't differentiate positions that "feel" different.



Author::::waynejr
DateTime::::2016-03-09T09:30:18Z
I bet a powerful AI might have calculated a response like yours. But a more superior AI would have calculated to just keep that to himself........



Author::::waynejr
DateTime::::2016-03-09T09:28:58Z
how many years did it take you to get to the point where you "solved" the problem? Isn't that learning? haha. Human ego and arrogance.



Author::::Ross Baldwin
DateTime::::2016-03-09T09:27:55Z
... and as I've said elsewhere, though left/right and player-side/opponent-side might be geometrically the same, they're very different from the players', and hence game's, perspective.



Author::::waynejr
DateTime::::2016-03-09T09:27:08Z
define love.



Author::::waynejr
DateTime::::2016-03-09T09:25:40Z
How about Calvinball? Or seven minutes in heaven! https://xkcd.com/1002/



Author::::waynejr
DateTime::::2016-03-09T09:24:36Z
Sandy, you could just dye your blond hair black and call that AI!



Author::::waynejr
DateTime::::2016-03-09T09:23:43Z
It does know sente. If you watch the live game today, you will see the guys discussion on how sente was being fought over. Essentially alphago used senta advantage to win the game.



Author::::Ross Baldwin
DateTime::::2016-03-09T09:22:41Z
No, Go boards are not exactly square (they're about 8% longer player-to-player than side-to-side, to compensate for perspective), so they're not diagonally symmetrical.



Author::::waynejr
DateTime::::2016-03-09T09:21:42Z
Although it has learned go, it is a general learning AI. Think about that.



Author::::waynejr
DateTime::::2016-03-09T09:20:11Z
Some humans ego's can't handle this. I suspect any job that can be taught will eventually be replaced.



Author::::waynejr
DateTime::::2016-03-09T09:18:27Z
19 x 19 is 361. The first move could be placed on any of those spots. You might be confused by meaning some of those moves would be a disadvantage. However, they are still moves.



Author::::Ross Baldwin
DateTime::::2016-03-09T08:56:05Z
While you might appear technically correct, that overlooks the intuitive aspects of the game. Go games are (virtually) never symmetrical, so positions to the left and right, and on the player's or opponent's side, do "feel" different. Are you also aware that the board grid is not exactly square, but rectangular (to allow for perspective on the players' views)? That eliminates some of the rotational symmetry of a truly square board.



Author::::Ross Baldwin
DateTime::::2016-03-09T08:48:28Z
Silly perhaps, but not illegal and not a guarantee of losing. At the very least, puzzling for your opponent!



Author::::AdTheDad
DateTime::::2016-03-09T08:15:36Z
Thanks for your reply. I don't doubt that it is a powerful system. But we do need to avoid confusing an AI system with some elements of learning with human-type intelligence. Learning via neural networks can also be considered as "system identification" where a computer model with many unknown parameters is refined using training data. That can produce very powerful systems but let's not conflate this with true intelligence which can be applied across many domains.



Author::::djhbrown
DateTime::::2016-03-09T01:20:00Z
actually, that's not strictly true, for 2 reasons:1. alphago does embody some Go knowledge; it learned kneejerk reactions through its training, and it "knows" that it has to look into the future, which it does by throwing dice in the context of some very very simple 3x3 patterns. As you know better than most, that's not enough to avoid blunders, so i expect we will see Lee taking advantage of its myopia.2. convolutional neural nets are being way overhyped by their propagandists; they did a fine job of learning to play Atari shootemups but they cant learn to play Pacman because even that simple game requires looking at the bigger picture, which cnns are unable to do. therefore they have no unusual value for other applications (like medical diagnosis) beyond that which is already available through established statistical methods for pattern recognition. on an aside, in 1975 i wrote a program that learned to diagnose liver disease that performed as well as clinicians; it used a general pattern formation method which could also learn to bid at Contract Bridge, and many others have made other general methods of pattern recognition, so cnns have not made a quantum leap in ai, no matter what their admen and spin doctors say.



Author::::Nedward Marbletoe
DateTime::::2016-03-08T23:43:06Z
JJ for the win!



Author::::Nedward Marbletoe
DateTime::::2016-03-08T23:41:55Z
I want to see a computer that can beat a human at "Go Fish."



Author::::Martyn Richard Jones
DateTime::::2016-03-08T21:25:29Z
This isn't really artifical intelligence is it... 



Author::::Declawed
DateTime::::2016-03-08T19:27:39Z
"But why not innovate directly in those application areas rather than in a game?"



Author::::Jeffrey Johnson
DateTime::::2016-03-08T19:23:32Z
There are not 361 possible opening moves in Go, as news reports keep stating. Because a Go board is horizontally, vertically, and diagonally symmetrical, there are actually 55 possible opening moves, compared to 20 in Chess. Just sayin'.



Author::::Declawed
DateTime::::2016-03-08T18:47:51Z
I don't expect humans to win against what is essentially the combined echo of every player the neural network studied. I do expect it to be wonderful for top players to improve their own game tho - it is made from the combined history of their game - it is the ultimate challenge.



Author::::John B
DateTime::::2016-03-08T18:07:06Z
I thought so too. But the recent promotion of self-driving cars for companies like Uber and self-service kiosks in retail and fast-food establishments seems to have re-awakened those old concerns.



Author::::vr13vr
DateTime::::2016-03-08T16:49:07Z
But why not innovate directly in those application areas rather than in a game? For example, if the neural networks are envisioned as a good tool for weather forecasting, why not do the research in that area instead of building the nn for games first and then figure out how to apply it elsewhere.



Author::::vr13vr
DateTime::::2016-03-08T16:45:18Z
Ok, I buy that argument.



Author::::CharlesArthur
DateTime::::2016-03-08T14:51:20Z
"Humans are capable of solving a problem they have never seen before (or nothing similar). This system needs to be trained on 1000s of Go game positions in order to learn what is a "good" or "bad" position and similarly to learn what moves to expect humans to play."



Author::::CharlesArthur
DateTime::::2016-03-08T14:42:42Z
No, that's not it. @HoldenCarver has it correct: the aim of Go is to end the game with more territory (empty space) than your opponent. "Dead" groups - the definition is a little complex, but briefly they're groups which only control a single point - don't have to be removed from the board (unlike chess), but they count to the opponent as if they were. The understanding of what is and is not "dead" can make reading the board at any point very perplexing for a beginner, and for those further up the ladder too.



Author::::Jon Diamond
DateTime::::2016-03-08T12:43:41Z
Unlike DeepBlue this project embeds very little Go knowledge in the software, so it's a better model for use in other application areas.



Author::::CatsLoveJazz
DateTime::::2016-03-08T11:33:54Z
No



Author::::theblueweasel
DateTime::::2016-03-08T10:51:10Z
With half a year elapsed I fully expect AlphaGo to have gone far enough to beat Lee Sedol. They just have to make up about 2 to 3 stones difference in strength. Slightly surprising that Lees team didn't request a hardware limit, and indeed, it would be interesting to see how well AlphaGo can perform running on a desktop machine. Will that ever come to pass - hard to imagine that they'll pass up the chance to cash in on the Go software market.



Author::::sandpeople80
DateTime::::2016-03-08T08:07:42Z
Well yes, yes it does involve intelligence. Given enough time I'm sure they will come up with some cures for certain cancers, they'd need us to be healthy in order to harvest us as slaves for the robotic overlords.



Author::::unclestinky
DateTime::::2016-03-08T07:56:13Z
I, for one, welcome our new robot overlords.



Author::::Applaudanum
DateTime::::2016-03-08T04:57:03Z
I remember Kasparov saying that the Deep Blue felt 'imposing' (or words to that effect).



Author::::Applaudanum
DateTime::::2016-03-08T04:52:32Z
The innovations made in completing the original task find applications in other areas. Think of the advancements in car technology thanks to car racing.



Author::::andymsmith
DateTime::::2016-03-08T02:57:40Z
Unless you believe that self-awareness is a phenomenon linked to a soul i.e. has some supernatural component, you will be dead wrong - but, such AI systems will not necessarily have empathy for humans although will doubtless learn to emulate it - psychopathic killer spiders ... skynet ...



Author::::Omniscience
DateTime::::2016-03-08T01:17:52Z
Hope this game doesn't overtax Alphago's processors



Author::::ID1279533
DateTime::::2016-03-08T01:05:39Z
I like your reply better than the article.



Author::::DUKEZZ
DateTime::::2016-03-08T00:58:28Z
Does winning at a game really involve intelligence? Tell me when AI can me up with a cure for cancer, then i"ll be impressed.



Author::::dotdotdashADSK
DateTime::::2016-03-08T00:27:07Z
I'm totally intrigued by this scenario and how each character would describe each word...could you elaborate?



Author::::vr13vr
DateTime::::2016-03-08T00:25:44Z
I used to like talking to humans too. But then the highway toll boothes became unmanned, the phone customer service became automated and the support phone numbers got buried deep inside the websites, so that customers don't find it too easy. The thing is that even if you like and trust a human better, your opinion isn't asked and you will still end up communicating with a machine.



Author::::vr13vr
DateTime::::2016-03-08T00:21:06Z
Like in the case of DeepBlue, a lot of effort and a talent was spent on... a game. Just for the sake of proving a point. The researches who worked on it built the names and hopefully their next jobs were highly paid. And the DeepBlue itself was eventually ditched. This DeepMind might be a similar thing but is this a good use of talent?



Author::::Knowles2
DateTime::::2016-03-08T00:14:48Z
Someone always talks eventually, one disgruntled programmer is all it would take. One back checking where in the world the grand masters were on that day. 



Author::::ragingbull
DateTime::::2016-03-08T00:05:50Z
AI progress carries on at a glacial pace. Even if the computer wins this time, it will be two decades to progress from one complex game to another.



Author::::Mark31415926
DateTime::::2016-03-08T00:05:23Z
The thing is: any time someone programs a computer to do something previously thought to require human intelligence, people will conclude that the task didn't really require intelligence, after all.



Author::::RobotOwl
DateTime::::2016-03-07T23:40:52Z
Perhaps I mean physically, not mathematically.



